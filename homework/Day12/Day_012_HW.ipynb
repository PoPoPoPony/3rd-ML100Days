{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load Day_012_HW.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# # 作業 : (Kaggle)鐵達尼生存預測\n",
    "# https://www.kaggle.com/c/titanic\n",
    "\n",
    "# # [作業目標]\n",
    "# - 試著模仿範例寫法, 在鐵達尼生存預測中, 觀察填補缺值以及 標準化 / 最小最大化 對數值的影響\n",
    "\n",
    "# # [作業重點]\n",
    "# - 觀察替換不同補缺方式, 對於特徵的影響 (In[4]~In[6], Out[4]~Out[6])\n",
    "# - 觀察替換不同特徵縮放方式, 對於特徵的影響 (In[7]~In[8], Out[7]~Out[8])\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "# 做完特徵工程前的所有準備 (與前範例相同)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "data_path = 'D:/VScode workshop/3rd-ML100Days/practice/Day12/data/'\n",
    "df_train = pd.read_csv(data_path + 'titanic_train.csv')\n",
    "df_test = pd.read_csv(data_path + 'titanic_test.csv')\n",
    "\n",
    "train_Y = df_train['Survived']\n",
    "ids = df_test['PassengerId']\n",
    "df_train = df_train.drop(['PassengerId', 'Survived'] , axis=1)\n",
    "df_test = df_test.drop(['PassengerId'] , axis=1)\n",
    "df = pd.concat([df_train,df_test])\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "#只取 int64, float64 兩種數值型欄位, 存於 num_features 中\n",
    "num_features = []\n",
    "for dtype, feature in zip(df.dtypes, df.columns):\n",
    "    if dtype == 'float64' or dtype == 'int64':\n",
    "        num_features.append(feature)\n",
    "print(f'{len(num_features)} Numeric Features : {num_features}\\n')\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "# 削減文字型欄位, 只剩數值型欄位\n",
    "df = df[num_features]\n",
    "train_num = train_Y.shape[0]\n",
    "df.head()\n",
    "\n",
    "\n",
    "# # 作業1\n",
    "# * 試著在補空值區塊, 替換並執行兩種以上填補的缺值, 看看何者比較好?\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 空值補 -1, 做羅吉斯迴歸\n",
    "df_m1 = df.fillna(-1)\n",
    "train_X = df_m1[:train_num]\n",
    "estimator = LogisticRegression()\n",
    "print(cross_val_score(estimator, train_X, train_Y, cv=5).mean())\n",
    "\n",
    "\"\"\"\n",
    "Your Code Here\n",
    "\"\"\"\n",
    "df_mean = df.fillna(df.mean())\n",
    "train_X = df_mean[:train_num]\n",
    "print(cross_val_score(estimator , train_X , train_Y , cv = 5).mean())\n",
    "\n",
    "\n",
    "df_mode = df\n",
    "for i in num_features : \n",
    "\tdf_mode[i].fillna(df_mode[i].mode()[0] , inplace = True)\n",
    "\n",
    "train_X = df_mode[:train_num]\n",
    "print(cross_val_score(estimator , train_X , train_Y , cv = 5).mean())\n",
    "\n",
    "\n",
    "# # 作業2\n",
    "# * 使用不同的標準化方式 ( 原值 / 最小最大化 / 標準化 )，搭配羅吉斯迴歸模型，何者效果最好?\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Your Code Here\n",
    "\"\"\"\n",
    "\n",
    "#原值\n",
    "estimator = LogisticRegression()\n",
    "print(cross_val_score(estimator , train_X , train_Y , cv = 5).mean())\n",
    "\n",
    "#min - max\n",
    "for i in num_features : \n",
    "\tval = df[i].values\n",
    "\tdf[i] = (val  - min(val)) / max(val) - min(val)\n",
    "print(cross_val_score(estimator , train_X , train_Y , cv = 5).mean())\n",
    "\n",
    "#標準化\n",
    "for i in num_features : \n",
    "\tval = df[i].values\n",
    "\tdf[i] = (val - val.mean()) / val.std()\n",
    "print(cross_val_score(estimator , train_X , train_Y , cv = 5).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
