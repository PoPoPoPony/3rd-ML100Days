{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load Day_031_HW.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# # 作業 : (Kaggle)鐵達尼生存預測\n",
    "\n",
    "# # [作業目標]\n",
    "# - 試著模仿範例寫法, 在鐵達尼生存預測中, 練習特徵重要性的寫作與觀察\n",
    "\n",
    "# # [作業重點]\n",
    "# - 仿造範例, 完成特徵重要性的計算, 並觀察對預測結果的影響 (In[3]~[5], Out[3]~[5]) \n",
    "# - 仿造範例, 將兩個特徵重要性最高的特徵重組出新特徵, 並觀察對預測結果的影響 (In[8], Out[8]) \n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "# 做完特徵工程前的所有準備 (與前範例相同)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data_path = os.getcwd() + \"/ml100_data/data/\"\n",
    "df = pd.read_csv(data_path + 'titanic_train.csv')\n",
    "\n",
    "train_Y = df['Survived']\n",
    "df = df.drop(['PassengerId', 'Survived'] , axis=1)\n",
    "df.head()\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "# 因為需要把類別型與數值型特徵都加入, 故使用最簡版的特徵工程\n",
    "LEncoder = LabelEncoder()\n",
    "MMEncoder = MinMaxScaler()\n",
    "for c in df.columns:\n",
    "    df[c] = df[c].fillna(-1)\n",
    "    if df[c].dtype == 'object':\n",
    "        df[c] = LEncoder.fit_transform(list(df[c].values))\n",
    "    df[c] = MMEncoder.fit_transform(df[c].values.reshape(-1, 1))\n",
    "df.head()\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "# 隨機森林擬合後, 將結果依照重要性由高到低排序\n",
    "estimator = RandomForestClassifier()\n",
    "estimator.fit(df.values, train_Y)\n",
    "feats = pd.Series(data=estimator.feature_importances_, index=df.columns)\n",
    "feats = feats.sort_values(ascending=False)\n",
    "print(feats)\n",
    "\n",
    "\n",
    "# ## 先用隨機森林對鐵達尼生存預測做訓練，再用其特徵重要性回答下列問題\n",
    "# \n",
    "# # 作業1\n",
    "# * 將特徵重要性較低的一半特徵刪除後，再做生存率預估，正確率是否有變化?\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# 高重要性特徵 + 隨機森林\n",
    "\"\"\"\n",
    "Your Code Here\n",
    "\"\"\"\n",
    "\n",
    "high_feature = feats[:(feats.shape[0] // 2)].index\n",
    "print(high_feature)\n",
    "\n",
    "train_X = MMEncoder.fit_transform(df[high_feature])\n",
    "print(cross_val_score(estimator, train_X, train_Y, cv=5).mean())\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# 原始特徵 + 隨機森林\n",
    "\n",
    "train_X = MMEncoder.fit_transform(df)\n",
    "cross_val_score(estimator, train_X, train_Y, cv=5).mean()\n",
    "\n",
    "\n",
    "# # 作業2\n",
    "# * 將特徵重要性最高的兩個特徵做特徵組合，是否能再進一步提升預測力?\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# 觀察重要特徵與目標的分布\n",
    "# 第一名              \n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.regplot(x=train_Y, y=df['Sex'], fit_reg=False)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# 第二名       \n",
    "\n",
    "sns.regplot(x=train_Y, y=df['Ticket'], fit_reg=False)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# 製作新特徵看效果\n",
    "\"\"\"\n",
    "Your Code Here\n",
    "\"\"\"\n",
    "df['new_feature'] = (df['Sex'] + df['Ticket']) / 2\n",
    "\n",
    "train_X = MMEncoder.fit_transform(df)\n",
    "print(cross_val_score(estimator, train_X, train_Y, cv=5).mean())\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
