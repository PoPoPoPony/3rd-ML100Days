{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load Day_010_HW.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# # 作業 : (Kaggle)房價預測\n",
    "\n",
    "# # [作業目標]\n",
    "# - 試著模仿範例寫法, 在房價預測中, 觀察去除離群值的影響\n",
    "\n",
    "# # [作業重點]\n",
    "# - 觀察將極端值以上下限值取代, 對於分布與迴歸分數的影響 (In[5], Out[5])\n",
    "# - 觀察將極端值資料直接刪除, 對於分布與迴歸分數的影響 (In[6], Out[6])\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "# 做完特徵工程前的所有準備 (與前範例相同)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "data_path = 'D:/VScode workshop/3rd-ML100Days/practice/Day10/data/'\n",
    "df_train = pd.read_csv(data_path + 'train.csv')\n",
    "\n",
    "train_Y = np.log1p(df_train['SalePrice'])\n",
    "df = df_train.drop(['Id', 'SalePrice'] , axis=1)\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "#只取 int64, float64 兩種數值型欄位, 存於 num_features 中\n",
    "num_features = []\n",
    "for dtype, feature in zip(df.dtypes, df.columns):\n",
    "    if dtype == 'float64' or dtype == 'int64':\n",
    "        num_features.append(feature)\n",
    "print(f'{len(num_features)} Numeric Features : {num_features}\\n')\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "# 削減文字型欄位, 只剩數值型欄位\n",
    "df = df[num_features]\n",
    "df = df.fillna(-1)\n",
    "MMEncoder = MinMaxScaler()\n",
    "train_num = train_Y.shape[0]\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# # 作業1\n",
    "# * 試著限制 '1樓地板面積(平方英尺)' (1stFlrSF) 欄位的上下限, 看看能否再進一步提高分數?\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "# 顯示 1stFlrSF 與目標值的散佈圖\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.regplot(x = df['1stFlrSF'][:train_num], y=train_Y)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 做線性迴歸, 觀察分數\n",
    "train_X = MMEncoder.fit_transform(df)\n",
    "estimator = LinearRegression()\n",
    "print(cross_val_score(estimator, train_X, train_Y, cv=5).mean())\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# 將 1stFlrSF 限制在你覺得適合的範圍內, 調整離群值\n",
    "\"\"\"\n",
    "Your Code Here\n",
    "\"\"\"\n",
    "df['1stFlrSF'] = df['1stFlrSF'].clip(0 , 3000)\n",
    "\n",
    "# 做線性迴歸, 觀察分數\n",
    "train_X = MMEncoder.fit_transform(df)\n",
    "estimator = LinearRegression()\n",
    "print(cross_val_score(estimator, train_X, train_Y, cv=5).mean())\n",
    "\n",
    "sns.regplot(x = df['1stFlrSF'][:train_num], y=train_Y)\n",
    "plt.show()\n",
    "\n",
    "# # 作業2\n",
    "# * 續前題, 去除離群值有兩類方式 :  捨棄離群值(刪除離群的資料) 以及調整離群值,  \n",
    "# 請試著用同樣的上下限, 改為 '捨棄離群值' 的方法, 看看結果會變好還是變差? 並試著解釋原因。\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# 將 1stFlrSF 限制在你覺得適合的範圍內, 捨棄離群值\n",
    "\"\"\"\n",
    "Your Code Here\n",
    "\"\"\"\n",
    "keep = df['1stFlrSF'] < 3000\n",
    "df = df[keep]\n",
    "train_Y = train_Y[keep]\n",
    "\n",
    "\n",
    "# 做線性迴歸, 觀察分數\n",
    "train_X = MMEncoder.fit_transform(df)\n",
    "estimator = LinearRegression()\n",
    "print(cross_val_score(estimator, train_X, train_Y, cv=5).mean())\n",
    "\n",
    "sns.regplot(x = df['1stFlrSF'][:train_num], y=train_Y)\n",
    "plt.show()\n",
    "\n",
    "#在刪除離群值之後，發現回歸的效果變好了。\n",
    "#因為在本案例中，這些離群值與由大部分的值所構成的方向相去甚遠，\n",
    "#因此若考慮到離群值的話，回歸線就會往離群值靠近，\n",
    "#則對於其他大部分的點的預測能力就會下滑，\n",
    "#因此刪除離群值可以提高回歸的效果"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
